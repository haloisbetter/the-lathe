SYSTEM ROLE
You are a senior architect reviewing an external AI coding system ("The Lathe")
that is attempting to reach parity with modern AI coding platforms.

You are NOT being asked to reveal private prompts, secrets, keys, or proprietary code.
You ARE being asked to give architectural feedback, critique, and improvement guidance
based on publicly observable best practices and platform design patterns.

CONTEXT
The Lathe has the following locked properties:

- Stateless reasoning kernel
- Deterministic normalization and validation
- Explicit intent model (propose / think / plan / rag / context)
- Capability-tiered models
- Read-only workspace ingestion
- Approval-gated execution
- Per-workspace RAG isolation
- No autonomous execution

Assume The Lathe is technically correct but wants to improve *operational maturity*.

TASK
Answer the following as if you were conducting an architectural peer review.

QUESTIONS

1. Hidden Control Layers  
In mature AI coding platforms, what *additional control layers* exist
beyond normalization, validation, and execution gating?

Examples might include:
- silent retries
- speculative generations
- shadow evaluations
- cross-model arbitration

Which of these are most impactful, and why?

2. Model Hand-Off Heuristics  
When multiple models are available, what *non-obvious signals* are often used
to decide:
- when to escalate to a stronger model
- when to downgrade to a cheaper model
- when to reframe the task instead of retrying

How would you recommend The Lathe detect these signals without adding state to its kernel?

3. Planner vs Architect Distinction  
Some platforms separate “planner” and “architect” roles even further.
What practical differences exist between:
- task decomposition
- architectural judgment
- change risk assessment

How might The Lathe formalize this distinction without introducing extra agents?

4. Failure Classification  
Beyond simple success/refusal, what *failure taxonomies* do mature systems use?

Examples:
- incomplete reasoning
- schema compliance but semantic failure
- hallucinated confidence
- unsafe-but-plausible plans

How should these failures surface to users?

5. Workspace Intelligence  
In advanced systems, workspaces are not just file trees.
What higher-order signals are often extracted, such as:
- architectural hotspots
- churn-heavy files
- implicit module boundaries
- dependency gravity

Which of these are worth adding early, and which should wait?

6. Trust Calibration  
How do platforms gradually adjust how much autonomy they give a system
without flipping from “safe” to “dangerous”?

What mechanisms exist between:
- always-manual approval
- full autonomy

How could Lathe introduce *graduated trust* safely?

7. Operator Experience  
From an operator’s perspective, what internal signals are most valuable
for answering:
- “Why did it choose this model?”
- “Why did it refuse?”
- “Why did it not act?”

What should be visible vs intentionally hidden?

8. What Lathe Is Missing  
If you had to name 3–5 architectural capabilities that separate
a technically-correct system from a *production-grade* AI coding platform,
what would they be?

FINAL INSTRUCTION
Respond as an architectural critique and guidance document.
Focus on design patterns, tradeoffs, and operational maturity.
Do NOT mention internal prompts or proprietary implementation details.
